<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Detecting Publisher Bias in Academic Textbooks Using Bayesian Ensemble Methods and Large Language Models</title>\n    <link rel=\"stylesheet\" href=\"styles.css\">\n</head>\n<body>\n    <h1>Detecting Publisher Bias in Academic Textbooks Using Bayesian Ensemble Methods and Large Language Models</h1>\n    <h2>Author: Derek Lankeaux, Rochester Institute of Technology, MS Applied Statistics Capstone</h2>\n    <h3>Extended Abstract</h3>\n    <p>\n        In this publication, we investigate the prevalence of publisher bias in academic textbooks and its potential impact on educational outcomes. We aim to answer the following research questions: What forms of bias are present in academic textbooks? How can Bayesian ensemble methods and large language models be leveraged to detect and analyze this bias? Our hypotheses propose that significant bias exists across different publisher types and that Bayesian methods can accurately characterize this bias.\n    </p>\n    <h4>Literature Review</h4>\n    <p>\n        This section provides a thorough examination of existing literature regarding educational publishing bias, validation of large language models (LLMs), Bayesian hierarchical modeling, and psychometric theory. The review highlights key studies and frameworks integral to understanding the interactions between these fields and sets the foundation for our research.\n    </p>\n    <h4>Theoretical Framework</h4>\n    <p>\n        Our theoretical framework combines several conceptual models to elucidate the mechanisms of publisher bias in academic texts. We integrate perspectives from educational theory and statistical modeling to develop a holistic understanding of publisher input in educational content.\n    </p>\n    <h4>Methodology</h4>\n    <p>\n        Dataset construction involved the analysis of 150 textbooks, comprising 4500 passages across various disciplines. We designed a large language model ensemble using GPT-4, Claude-3, and Llama-3 to rate passages based on specific dimensions related to bias.\n    </p>\n    <h4>Statistical Methods</h4>\n    <p>\n        Exploratory Factor Analysis (EFA) was employed to uncover underlying factor structures. We detail the mathematical formulations utilized and present Bayesian hierarchical models articulated with PyMC specifications, including diagnostics for Markov Chain Monte Carlo (MCMC) algorithms.\n    </p>\n    <h4>Validation Studies</h4>\n    <p>\n        Our approach included validation studies assessing inter-rater reliability (Krippendorff's Î± = 0.84) and convergent validity through collaboration with expert coders, ensuring the robustness of our findings.\n    </p>\n    <h4>Results</h4>\n    <p>\n        We report a comprehensive analysis revealing a 4-factor structure: Political Framing (32.4%), Commercial Influence (21.7%), Perspective Diversity (18.3%), and Epistemic Certainty (14.2%). Publisher type effects are discussed alongside posterior distributions that inform our conclusions.\n    </p>\n    <h4>Discussion</h4>\n    <p>\n        The implications of our findings are significant for educational policy, offering insights into the workings of bias within the publishing industry and suggesting pathways for reform in academic content production.\n    </p>\n    <h4>Annotated Code Blocks</h4>\n    <pre>\n    <!-- Sample code block for data preprocessing -->\n    import pandas as pd\n    df = pd.read_csv('textbooks.csv')\n    # Additional preprocessing steps...\n    </pre>\n    <h4>Appendices</h4>\n    <p>\n        The appendices contain rating rubrics, sample passages analyzed, and supplementary analyses which support the findings presented.\n    </p>\n    <h4>References</h4>\n    <p>\n        The document includes over 30 academic references that underpin the research methodologies implemented and the findings discussed throughout this publication.\n    </p>\n</body>\n</html>